{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](../../README.md)\n",
    "\n",
    "### Data Wrangling\n",
    "\n",
    "This is a demonstration of data wrangling using [Pandas](https://pandas.pydata.org/) the library for data analysis and manipulation.\n",
    "\n",
    "This Jupyter Notepad demonstrates different processes you can apply to your data to prepare it for feature engineering and model training. For this demonstration we will wrangle the diabetes data set you previewed in the last Jupyter Notebook.\n",
    "\n",
    "> [!Note]\n",
    "> None of these processes are destructive to the source CSV as long as you save the modified data to a new CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import frameworks\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Store the data as a local variable\n",
    "\n",
    "The data frame is a Pandas object that structures your tabular data into an appropriate format. It loads the complete data in memory so it is now ready for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"2.1.2.diabeties_sample_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with null values\n",
    "\n",
    "Null values during data analysis can cause runtime errors and unexpected results. It is important to identify null values and deal with them appropriately before training a model.\n",
    "\n",
    "The `isnull().sum()` method call returns the null values in any column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "6364bff2-0e05-4262-9133-fc8d1f268318",
       "rows": [
        [
         "DoB",
         "0"
        ],
        [
         "DoT",
         "0"
        ],
        [
         "SEX",
         "1"
        ],
        [
         "BMI",
         "0"
        ],
        [
         "BP",
         "0"
        ],
        [
         "TC",
         "0"
        ],
        [
         "BGU",
         "0"
        ],
        [
         "FDR",
         "0"
        ],
        [
         "Target",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 9
       }
      },
      "text/plain": [
       "DoB       0\n",
       "DoT       0\n",
       "SEX       1\n",
       "BMI       0\n",
       "BP        0\n",
       "TC        0\n",
       "BGU       0\n",
       "FDR       0\n",
       "Target    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have null data there are many ways to deal with the empty/null values. These are the two most common approaches.\n",
    "1. Remove any row with a null value with a `dropna()` method call.\n",
    "2. Replace missing values with another value with a `fillna()` method call. Generally, we use mean value for numerical columns because it may cause minimal changes in your mathematical analysis while maintaining the original size of the data.\n",
    "\n",
    "Students should reflect why this example removes the null 'SEX' but replacing the mean 'Target'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "206a6bed-6d2e-4994-8c34-6b86c80d552a",
       "rows": [
        [
         "DoB",
         "0"
        ],
        [
         "DoT",
         "0"
        ],
        [
         "SEX",
         "0"
        ],
        [
         "BMI",
         "0"
        ],
        [
         "BP",
         "0"
        ],
        [
         "TC",
         "0"
        ],
        [
         "BGU",
         "0"
        ],
        [
         "FDR",
         "0"
        ],
        [
         "Target",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 9
       }
      },
      "text/plain": [
       "DoB       0\n",
       "DoT       0\n",
       "SEX       0\n",
       "BMI       0\n",
       "BP        0\n",
       "TC        0\n",
       "BGU       0\n",
       "FDR       0\n",
       "Target    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Null values\n",
    "data_frame = data_frame.dropna(subset=['SEX'])\n",
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "de82ae2d-7db3-4339-bcf4-f8395d98b38e",
       "rows": [
        [
         "DoB",
         "0"
        ],
        [
         "DoT",
         "0"
        ],
        [
         "SEX",
         "0"
        ],
        [
         "BMI",
         "0"
        ],
        [
         "BP",
         "0"
        ],
        [
         "TC",
         "0"
        ],
        [
         "BGU",
         "0"
        ],
        [
         "FDR",
         "0"
        ],
        [
         "Target",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 9
       }
      },
      "text/plain": [
       "DoB       0\n",
       "DoT       0\n",
       "SEX       0\n",
       "BMI       0\n",
       "BP        0\n",
       "TC        0\n",
       "BGU       0\n",
       "FDR       0\n",
       "Target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace Null values with the mean value for the column\n",
    "data_frame['Target'] = data_frame['Target'].fillna(data_frame['Target'].mean())\n",
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Duplicates\n",
    "\n",
    "Duplicate data can have detrimental effects on your machine learning models and outcomes, such as reducing data diversity and representativeness, which can lead to overfitting or biased models.\n",
    "\n",
    "The `duplicated().sum()` method call returns the count of duplicate rows in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `drop_duplicates()` method call can be then stored back onto the data_frame variable removing the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = data_frame.drop_duplicates()\n",
    "data_frame.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace data\n",
    "\n",
    "We can run a lambda function on a column to modify its values. For a simple example, letâ€™s convert the Sex to lowercase. To run a function over a complete column, we can use the apply method which iterates over each row and modifies the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SEX",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "afa833f3-0790-472b-a3e7-0c6c832ccf9c",
       "rows": [
        [
         "0",
         "female"
        ],
        [
         "1",
         "female"
        ],
        [
         "2",
         "male"
        ],
        [
         "3",
         "male"
        ],
        [
         "4",
         "male"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/plain": [
       "0    female\n",
       "1    female\n",
       "2      male\n",
       "3      male\n",
       "4      male\n",
       "Name: SEX, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['SEX'] = data_frame['SEX'].apply(lambda x: x.lower())\n",
    "data_frame['SEX'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that there are no data entry errors by the `unique()` method call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male', 'girl'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['SEX'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['SEX'] = data_frame['SEX'].apply(lambda gender: 'male' if gender.lower() == 'male' else 'female')\n",
    "data_frame['SEX'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove outliers\n",
    "\n",
    "Outliers can skew your analysis on numerical columns, and it is important to remove them. We can use the 25th and 75th quartile on numerical data, to get the inter-quartile range. This allows us to estimate an acceptable range, and we can then filter out any values outside this range. Mathematically, outliers are values occurring outside 1.5 times the interquartile range (IQR) from the first quartile (Q1) or third quartile (Q3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    442.000000\n",
      "mean      94.687738\n",
      "std       14.224409\n",
      "min       51.000000\n",
      "25%       84.000000\n",
      "50%       93.000000\n",
      "75%      105.000000\n",
      "max      141.000000\n",
      "Name: BP, dtype: float64\n",
      "Outliers are a BP above 136.5 or below 52.5\n"
     ]
    }
   ],
   "source": [
    "#get the inter-quartile range on the salary column\n",
    "print(data_frame['BP'].describe())\n",
    "Q1 = data_frame['BP'].quantile(0.25)\n",
    "Q3 = data_frame['BP'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(f'Outliers are a BP above {Q3 + IQR * 1.5} or below {Q1 - IQR * 1.5}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    439.000000\n",
      "mean      94.583098\n",
      "std       13.790260\n",
      "min       62.000000\n",
      "25%       84.000000\n",
      "50%       93.000000\n",
      "75%      105.000000\n",
      "max      133.000000\n",
      "Name: BP, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Filter salaries within the acceptable range\n",
    "data_frame = data_frame[(data_frame['BP'] >= Q1 - 1.5 * IQR) & (data_frame['BP'] <= Q3 + 1.5 * IQR)]\n",
    "print(data_frame['BP'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling features to a common range\n",
    "\n",
    "Scaling the features makes it easier for machine learning algorithms to find the optimal solution, as the different scales of the features do not influence them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "BMI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BGU",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FDR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Target",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "f2c34427-6eb2-41ec-a207-5b70492ae95b",
       "rows": [
        [
         "count",
         "439.0",
         "439.0",
         "439.0",
         "439.0",
         "439.0",
         "439.0"
        ],
        [
         "mean",
         "26.36127562642369",
         "0.4656835052927777",
         "4.069111617312073",
         "91.2756264236902",
         "1.0660592255125285",
         "152.03032779349724"
        ],
        [
         "std",
         "4.42830293252537",
         "0.1622383487990588",
         "1.2944916259694044",
         "11.49246817110124",
         "0.8318492938182269",
         "77.29809562107009"
        ],
        [
         "min",
         "18.0",
         "0.08235294117647059",
         "2.0",
         "58.0",
         "0.0",
         "25.0"
        ],
        [
         "25%",
         "23.15",
         "0.3411764705882353",
         "3.0",
         "83.5",
         "0.0",
         "86.5"
        ],
        [
         "50%",
         "25.7",
         "0.4470588235294118",
         "4.0",
         "91.0",
         "1.0",
         "140.0"
        ],
        [
         "75%",
         "29.25",
         "0.5882352941176471",
         "5.0",
         "98.0",
         "2.0",
         "213.0"
        ],
        [
         "max",
         "42.2",
         "0.9176470588235294",
         "9.09",
         "124.0",
         "3.0",
         "346.0"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>TC</th>\n",
       "      <th>BGU</th>\n",
       "      <th>FDR</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>439.000000</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>439.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26.361276</td>\n",
       "      <td>0.465684</td>\n",
       "      <td>4.069112</td>\n",
       "      <td>91.275626</td>\n",
       "      <td>1.066059</td>\n",
       "      <td>152.030328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.428303</td>\n",
       "      <td>0.162238</td>\n",
       "      <td>1.294492</td>\n",
       "      <td>11.492468</td>\n",
       "      <td>0.831849</td>\n",
       "      <td>77.298096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.150000</td>\n",
       "      <td>0.341176</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>83.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>86.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.700000</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.250000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>213.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42.200000</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>346.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              BMI          BP          TC         BGU         FDR      Target\n",
       "count  439.000000  439.000000  439.000000  439.000000  439.000000  439.000000\n",
       "mean    26.361276    0.465684    4.069112   91.275626    1.066059  152.030328\n",
       "std      4.428303    0.162238    1.294492   11.492468    0.831849   77.298096\n",
       "min     18.000000    0.082353    2.000000   58.000000    0.000000   25.000000\n",
       "25%     23.150000    0.341176    3.000000   83.500000    0.000000   86.500000\n",
       "50%     25.700000    0.447059    4.000000   91.000000    1.000000  140.000000\n",
       "75%     29.250000    0.588235    5.000000   98.000000    2.000000  213.000000\n",
       "max     42.200000    0.917647    9.090000  124.000000    3.000000  346.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_feature = 'BP'\n",
    "\n",
    "#the minimum value with space for outliers\n",
    "MIN_BP = 55\n",
    "\n",
    "#the maximum value with space for outliers\n",
    "MAX_BP = 140\n",
    "\n",
    "#scale features\n",
    "data_frame[scale_feature] = [(X - MIN_BP) / (MAX_BP - MIN_BP) for X in data_frame[scale_feature]]\n",
    "\n",
    "data_frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!important]\n",
    "> You need to save the calculations for each dataset you scale for scaling new values for prediction. Use [2.1.2.data.records.md](2.1.2.data.records.md) to record this information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the wrangled data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.to_csv('../2.2.Feature_Engineering/2.2.1.wrangled_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
